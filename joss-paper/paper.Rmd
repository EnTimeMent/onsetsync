---
# Example from https://joss.readthedocs.io/en/latest/submitting.html
title: 'onsetsync: An R Package for Onset Synchrony and Periodicity Analysis'
tags:
  - R
  - music
  - entrainment
  - periodicity
  - synchrony
authors:
  - name: Tuomas Eerola
    orcid: 0000-0002-2896-929X
    affiliation: 1 # (Multiple affiliations must be quoted)
  - name: Martin Clayton
    orcid: 0000-0000-0000-0000
    affiliation: 1
affiliations:
 - name: Department of Music, Durham University
   index: 1
citation_author: Eerola et. al.
date: 1 July 2021
year: 2021
bibliography: paper.bib
output: rticles::joss_article
#csl: apa.cls
citation_package: "default"
keep_tex: FALSE
journal: JOSS
---

# 1 Introduction and statement of need

Music performance relies on tight yet flexible timing between the performers. This entrainment between two or more performers can be analysed from the note onsets obtained from recorded performances. The onset synchrony characterises the timing accuracy and dynamics from the onsets of the performance. The synchrony between performers is influenced by various factors such as the genre of music, performer skill level, intention, and phrase and beat structures of the music. The analysis of synchrony in music benefits from shared tools as there are a number of common operations that need to be carried in every dataset (e.g., comparing individual onsets to a virtual beat, or assessing the synchrony across other variables such as tempo, metrical hierarchy, or phrasing) and the amount of datasets containing raw onsets has recently increased.


## 1.1 Statement of need

`onsetsync` is a R package for musical dynamics involving synchrony. There are functions for common operations such as adding isochronous beats based on metrical structure, adding annotations, calculating classic measures of synchrony between two performers, and assessing periodicity of the onsets, and visualising synchrony across cycles, time, or another property. These functions will make the analyses of the onset corpora more transparent and comparable and will allow more scholars to carry out exploratory investigation of entraiment in music with minimal skills in computing. 

`onsetsync` was designed to be used by both empirical music researchers and by students in courses on music and science and empirical musicology.

> NOTE 1: Here more about synchronization and entrainment. For instance, sensorimotor synchronisation [@repp2008sensorimotor], synchrony indices from Wing, or from @polak2016both. And we need to mention a real world example such as [@lucas2011inter] and cue in Martin's influential papers included as well [@clayton2020;@clayton_et_al_2018b].

And the EMR article [@Clayton2020emr].

> NOTE 2: Different indices for asynchrony, absolute asynchrony, relative asynchrony? We talk about synchrony in all examples, though. 

## 1.2 Availability

```{r secret_load,eval=TRUE,echo=FALSE}
# LOADS THIS SECRECTLY FROM THE LOCAL FOLDER
library(onsetsync)
ver <- packageVersion('onsetsync')
```

`onsetsync` is available at Github and can be loaded and installed using the code below. The current version is `r ver`.


```{r availability,eval=FALSE}
library(devtools)
devtools::install_github("tuomaseerola/onsetsync")
library(onsetsync)
packageVersion('onsetsync')
```


# 2 Core functionality

`onsetsync` has five types of functionalities; (1) adding information, (2) summarising onset data, (3) calculating synchrony, (4) estimating periodicity, and (5) visualising all of these. Here we will take example onset data from an open access repository at Open Science Framework (OSF) involving Cuban Son and Salsa performances, annotated and processed as part of [Interpersonal Entrainment in Music Performance](https://musicscience.net/projects/timing/iemp/) project available at [https://osf.io/sfxa2/](https://osf.io/sfxa2/). We will carry out operations that demonstrate all the functionalities of the package.

Note that `onsetsync` is not dedicated to extraction of onsets from audio as that can be done in other packages (e.g. [Librosa](https://librosa.org), or [Mir Toolbox for Matlab](https://www.jyu.fi/hytk/fi/laitokset/mutku/en/research/materials/mirtoolbox), or [Sonic Visualiser](https://www.sonicvisualiser.org) using well-known onset detection algorithms. Here we take it as granted that we have extracted the onsets in some of these programs, probably checked them by hand, and we have the onset times recorded into csv files. 

> NOTE 3: It might be beneficial to be able to replicate some analyses reported in the IEMP papers (Clayton et al 2018 in Musicae Scientiae is the best one, although the Music Perception one could also work) but coordinating this might be a pain (and the results might not be identical).

## 2.1 Read data from an online repository

```{r, results='hide', message=FALSE, warning=FALSE,echo=FALSE}
library(dplyr)
library(ggplot2)
library(reshape2)
library(httr)
```

Retrieve onset data and annotation of metre from an online repository of performances (IEMP at OSF, insert link and refs):

```{r getdata1,message=FALSE,warning=FALSE}
CSS_Song2_Onset <- get_OSF_csv('8a347') # Onsets
knitr::kable(head(CSS_Song2_Onset[,1:8,]),format = "simple")

CSS_Song2_Metre <- get_OSF_csv('4cdpr') # Annotations
CSS_Song2_Onset <- dplyr::select(CSS_Song2_Onset,
                                 Label.SD,SD,Clave,Bass,Guitar,Tres) 
```

The Table 1 shows a portion of the onset data structure where the last three columns refer to the onset times of the specific instruments (`Clave`, `Bass`, and `Guitar`). Note that we only show the first eight columns and 6 rows. The first five columns are meta-data, referring to the `Piece`, beat sub-divisions (`SD` and `Label.SD`, which is a unique label combining cycle and beat information), `Section` indicating the specific part of the piece. Finally, in this example we have `Clave_` column, which is a reference to a clave pattern. The onset times for the instruments are recorded in seconds, although we prefer to use milliseconds in the analyses of synchrony to avoid reporting many digits.

In the second data frame (`CSS_Song2_Metre`) we have annotations, namely the cycle times, which are the exact time when the cycles start (containing all sub-divisions of the beat). This is important information and want to combine the actual onsets and the cycles many analyses. 

HERE IT COULD BE EXPLAINED IN MORE DETAILS WHERE THE CYCLE INFORMATION COMES FROM.

> Note 4: We need to have some datasets that with the package to avoid always loading the stuff from OSF.

## 2.2 Combine onsets and annotations

As the onsets and annotations are in different files, let's first combine the raw onset and annotation with `onsetsync`. Here we first add annotations about the cycles into the onset data and then we also add isochronous beat times to the data frame, since are useful reference points for future calculations.

```{r pre,echo=TRUE,results='asis'}
library(onsetsync)
packageVersion('onsetsync')

# Add annotations about the cycle to the data frame
CSS_Song2 <- add_annotation(df = CSS_Song2_Onset,
                            annotation = CSS_Song2_Metre$Cycle,
                            time = CSS_Song2_Metre$Time,
                            reference = 'Label.SD')
# Add isochronous beats to the data frame
CSS_Song2 <- add_isobeats(df = CSS_Song2, 
                          instr = 'CycleTime', 
                          beat = 'SD')

print(knitr::kable(head(CSS_Song2),format = "simple",digits = 2))
```

At this point we have the basic elements for most analyses shown in Table 3; We have the onset data (coded under instrument names, here `Clave`, `Bass`, and `Tres`) and information about the beat cycles  (`CycleTime` and `Cycle`), and we also have timing information for isochronous beat divisions (`Isochronous.SD.Time`). 

These virtual beat structures that are now based on annotations can be systematically off by a certain amount, so perhaps some it is advantageous for some analyses to infer the timing information related to the beat structure from the existing onsets themselves and not rely on external reference. `onsetsynch_add_isobeats` can also accomplish this if given the instruments from which it will calculate the mean onset time for the first beat of the cycle, which will be used to set the isochronous beat timings for the rest of the beats within the cycle.

Before moving onto the analysis, let's summarise the onset structures in this piece.

```{r summary_period,results='asis'}
tab1 <- summarise_onsets(df = CSS_Song2, 
                         instr = c('Clave','Bass','Guitar','Tres'))
print(knitr::kable(tab1,digits = 1,
     caption = 'Descriptives for the onset time differences (ms)'))
```

Table 4 summarise these and we can see that we have a varying number of onsets in different instruments and the typical time difference between the onsets range from X to Y. We will look at the periodicity analysis later, but these basics are good to keep in mind when analysing synchrony.

Let's move on and explore the synchrony between the performers.

## 2.3 Analysis of synchrony

### 2.3.1 Synchrony with the beat sub-divisions

As a broad overview, we can visualise the relative synchrony to equal division subdivision of the beat for each instrument across the time. This gives a summary about when the instrument are playing relative to the beat division and the sections of the song. 

```{r synch2isochron,fig.width=9, fig.height=7.0,fig.cap='Onsets arranged for beat sub-divisions for four instruments across the whole piece.'}
fig1 <- plot_by_beat(df = CSS_Song2, 
                     instr = c('Bass','Clave','Guitar','Tres'), 
                     beat = 'SD', 
                     virtual='Isochronous.SD.Time',
                     pcols=2)
print(fig1)
```

This six-minute piece does not contain much variation in the patterns of onsets across the beats. We can see that the bass is elaborating the beats during the last minute or so while the clave, guitar and tres keep playing their patterns throughout the piece.

Alternatively, we can show how much the onsets deviate from the isochronous beat or from the mean onset times. Here's an example of the former for two instruments, bass and tres.

```{r synch2isochron2,fig.width=9, fig.height=5.5,fig.cap='Deviations from beat sub-divisions.'}
fig2 <- plot_by_beat(df = CSS_Song2,
                     instr = c('Bass','Tres'),
                     beat = 'SD',
                     virtual = 'Isochronous.SD.Time', 
                     pcols=1,
                     griddeviations = TRUE)
print(fig2)
```

Perhaps we do not want to follow the trajectories across time but are more interested in finding out the overall synchrony of the instruments across the beat sub-divisions. A boxplot of the synchronies can be obtained using the same function by adding box is TRUE parameter:

```{r synch2isochron3,fig.width=7, fig.height=3.5,fig.cap='Synchrony acrocc sub-division of beat'}
fig3 <- plot_by_beat(df = CSS_Song2,
                     instr = 'Tres',
                     beat = 'SD',
                     virtual = 'Isochronous.SD.Time', 
                     pcols=1,
                     griddeviations = TRUE,
                     box = TRUE)
print(fig3)
```

### 2.3.2 Synchrony between the instruments

To what degree are the pairs of instruments synchronised in this example? Since the instruments usually play widely different amounts of onsets in a piece, and these are bound to be at different beats sub-divisions, the mutual amount of comparable onsets for each pair varies often dramatically. In order to keep the mean and standard deviations comparable, we will randomly sample joint onsets for both instruments. 

```{r paired1}
set.seed(1201) # set random seed
N <- 100 # Let's select 100 onsets
d1 <- sync_sample_paired(CSS_Song2,'Clave','Bass',N,1,'SD',TRUE)
print(paste('Mean asynchrony of',round(mean(d1$asynch*1000),1),
    'ms & standard deviation of',round(sd(d1$asynch*1000),1),'ms'))
```
In this example there are at least 241 shared onset times between the clave and the bass. Let's redo the random sampling 10 times so we get more observations whilst still always main the sample of 100 joint onsets.
```{r paired2}
d10 <- sync_sample_paired(CSS_Song2,'Clave','Bass',N,10,'SD',TRUE)
print(paste('Asynchrony M =',round(mean(d10$asynch*1000),1),
      'ms & SD =',round(sd(d10$asynch*1000),2)))
```

You can carry out this operation easily for all possible pairings of the instruments with `sync_execute_pairs` and visualise the results with a related function (`plot_by_pair`).

```{r fig4,fig.width=4.5, fig.height=4.5, warning=FALSE,fig.cap='Asynchronies across the instrument pairs.'}
inst<-c('Clave','Bass','Guitar','Tres') # Define instruments 
dn <- sync_execute_pairs(CSS_Song2,inst,N,10,'SD')
fig4 <- plot_by_pair(dn)  # plot
print(fig4)  
```

In Figure 4 we see how different pairs of instruments have different mutual synchronies; Bass is consistently ahead of guitar and clave is behind the tres to pick some of the extreme examples from the visualisation.

It is also possible to carry out the comparison with across the beat sub-divisions. Here we choose only three instruments to keep the number of comparisons sensible for a plot (instruments times sub-divisions) and keep the rest of the analysis settings the same.

```{r fig5, fig.width=7.5, fig.height=5.0, warning=FALSE,fig.cap='Asynchronies across the beat sub-divisions and instrument pairs.'}
inst<-c('Bass','Guitar','Tres')
dn <- sync_execute_pairs(CSS_Song2,inst,N,10,'SD')
fig5 <- plot_by_pair(dn,bybeat=TRUE)
print(fig5)  
```

From the breakdown of the sub-divisions across the instruments shown in Figure 5, it is clear that the first sub-division usually has the least amount of asynchrony and less variation in asynchrony, but the actual patterns fluctuate between instrument pairs.

Let's calculate statistics (t-test) about the onset synchronies for these instrument pairs. 

```{r stats,results='asis'}
table3 <- data.frame(stats_by_pair(dn))
print(knitr::kable(table3,digits = 1))
```

Table 5 suggests all deviations between these instrument combinations are statistically significant (and this includes a correction for multiple comparisons).

\pagebreak

### 2.3.3 Synchrony with other variables

It is relatively straightforward to explore whether synchrony is linked with another variable. Some meaningful comparisons between synchrony could be carried out with duration of the cycles (as a proxy of musical tempo), dynamics, or note density. Next we try this out with the tempo, here defined as the duration of each cycle in seconds.

```{r sync_vs_tempo,fig.width=3, fig.height=3, fig.cap='Synchrony vs tempo.'}

CSS_Song2 <- CSS_Song2 %>%
  group_by(Cycle) %>%
  mutate(Duration = max(Isochronous.SD.Time) - min(Isochronous.SD.Time))
CSS_Song2 <- ungroup(CSS_Song2) # drop grouping structure

d1 <- sync_sample_paired(df = CSS_Song2,
                         INSTR1 = 'Clave',
                         INSTR2 = 'Bass',
                         N = 200,
                         BNum = 1, 
                         beat = 'Duration')
fig6 <- plot_by_variable(d1,
                       meta = 'Clave-Bass Synchrony',
                       xlab='Cycle duration (in s)')
print(fig6)
```


As figure 6 shows, there does not seem to be any clear associations between the synchrony between bass and clave and the tempo as measured by the cycle durations.

### 2.3.4 Synchrony across separate performances

So far our analysis has consider one examples and synchrony within the example. We can take two different performances, choose the instrument pairings, and carry out the desired comparison, provided that this is conceptually meaningful and technically feasible (similar types of onset and annotation data available). In this example, the column names are slightly different to the first example and the extract is taken from the middle of a performance, so the timing information could be adjusted to remove the long lead time until the first onset.

```{r moredat, eval=TRUE}

invisible(GET("https://osf.io/a4yw7/?action=download", 
    write_disk("CSS_Song3_Onsets_Selected.csv", overwrite = TRUE)))
CSS_Song3_Onset<-read.csv("CSS_Song3_Onsets_Selected.csv",
                          header=T, sep=",")
CSS_Song3_Onset <- dplyr::select(CSS_Song3_Onset,
                                 Label.SD,SD,Clave,Bass,Guitar,Tres)

invisible(GET("https://osf.io/czu6m/?action=download", 
              write_disk("CSS_Song3_Metre.csv", overwrite = TRUE)))
CSS_Song3_Metre <- read.csv("CSS_Song3_Metre.csv", header=T, sep=",")

# Add annotations
CSS_Song3 <- add_annotation(df=CSS_Song3_Onset,
                            annotation = CSS_Song3_Metre$Cycle,
                            time = CSS_Song3_Metre$Time,
                            reference = 'Label.SD')
# Add isochronous beats
CSS_Song3 <- add_isobeats(df=CSS_Song3,instr = 'CycleTime', beat = 'SD')
```

Now that we have another Cuban Salsa performance from the same band in a data frame called `CSS_Song3`, let's calculate the synchrony across the instruments in both performances.

```{r compare,echo=TRUE,eval=TRUE}
d1 <- sync_sample_paired(CSS_Song2,'Tres','Bass',N=0,beat='SD') 
d1 <- data.frame(d1); d1$dataset<-'CSS_Song2'

d2 <- sync_sample_paired(CSS_Song3,'Tres','Bass',N=0,beat='SD')
d2 <- data.frame(d2);d2$dataset<-'CSS_Song3'

D <- suppressMessages(full_join(d1,d2)); # merge the outputs
D$beatL<-factor(D$beatL); D$dataset<-factor(D$dataset) # as factor
D$abs_asynch_ms <- abs(D$asynch*1000) # convert into absolute errors and to ms
```

After these operations, the data frame `D` contains onset synchronies from both performances. We can create a simple boxplot of the combined data ignoring the beat sub-divisions, but then also calculate a simple summary statistics about the differences and show the means across the sub-divisions.

Let's first look at the means. 

```{r showmeans, eval=TRUE,results='asis'}
grandmeans <- summarise(group_by(D,dataset),
                        M = mean(abs(asynch*1000)),
                        SD = sd(abs(asynch*1000)))
knitr::kable(grandmeans,
             caption="Grand mean asynchronies.",
             format="simple", digits=2)
# Summary statistics
output <- aov(abs(asynch) ~ beatL * dataset, data=D)
print(knitr::kable(xtable::xtable(output), caption = "Anova table."))
```

There seems to be a statistically significant difference between the pieces in synchrony but no main effect of beat sub-division. However, the interaction between the piece and sub-division seems to be significant, so some of the beats differ between the two pieces.

```{r showplot,eval=TRUE,fig.width=3.0, fig.height=3.0,fig.cap='Absolute asynchronies across the piece.'}
fig10 <- plot_by_dataset(D,'abs_asynch_ms','dataset', box = TRUE)
print(fig10)
```

### 2.3.5 Synchrony across time

Appy the analyses of synchrony across specific segments (cycle, section, etc.). Let's look at synchrony between tres and bass across time (across cycles).

> NOTE 6: REDO THE PLOTS

```{r sync_time1, fig.width=6, fig.height=3.5, fig.cap='Synchrony across cycles.'}
d2 <- sync_sample_paired(df = CSS_Song2,
                         INSTR1 = 'Tres',
                         INSTR2 = 'Bass',
                         N = 0,
                         beat = 'Cycle')
tmp <- data.frame(asynch=d2$asynch*1000,Cycle=d2$beatL)

#fig12 <- plot_by_var_time(df=tmp,var1 = 'Cycle',var2 = 'asynch')

fig12 <- ggplot(tmp,aes(x=Cycle,y=asynch))+
  geom_point(colour='orange') +
  stat_smooth(aes(x=Cycle,y=asynch), method = lm, 
              formula = y ~ splines::bs(x, 12), se = TRUE)+
  xlab('Cycle')+
  ylab('Asynchrony (ms)')+
  theme_linedraw()
print(fig12)
```

We can also explore whether the synchrony (here _absolute asynchrony_) might be related to _tempo_ changes across time. Here define the tempo by the length of the cycles.

```{r sync_time2, fig.width=6, fig.height=3.0,fig.cap='Absolute asynchrony across cycle length.'}

CSS_Song2 <- CSS_Song2 %>%
  group_by(Cycle) %>%
  mutate(Duration = max(Isochronous.SD.Time) - min(Isochronous.SD.Time))

d2 <- sync_sample_paired(CSS_Song2,'Tres','Bass',N=0,beat='Duration')
d3 <- sync_sample_paired(CSS_Song2,'Tres','Bass',N=0,beat='Isochronous.SD.Time')
tmp <- data.frame(asynch=d2$asynch*1000,Duration=d2$beatL,Time=d3$beatL)

fig13 <- ggplot(tmp,aes(x=Time,y=abs(asynch),colour=Duration))+
  geom_line() +
  stat_smooth(aes(x=Time,y=abs(asynch)), method = lm, 
              formula = abs(y) ~ splines::bs(x, 12), se = FALSE)+
  xlab('Time (min:sec)')+
  ylab('Absolute asynchrony (ms)')+
  scale_x_time(breaks = seq(0,350,by=60))+
  scale_color_continuous(name='Cycle Duration',low='red',high = 'blue')+
  theme_linedraw()+
  theme(legend.position="top")

print(fig13)  
```

It seems that there could be some association between increase in tempo and increased asynchrony (at least there is an increase in both around 05:10-5:30).

\pagebreak

## 2.4 Analysis of periodicity

Let's take the bass onsets in the first example (CSS_Song2) and look at the first 20 seconds. Let's add the cycles in the plot to make the pattern more visible.

```{r discrete_rep,echo=TRUE,fig.width=5.5,fig.height=2,fig.cap='Discrete onset times for bass.'}
extract <- dplyr::filter(CSS_Song2,Guitar >= 0 & Guitar < 10)
fig11 <- plot_timeline(data=extract, instr = 'Guitar')
print(fig11)
```

We can see that bass is keeping steady beat, playing a sequence of two notes separated by about 0.40 seconds with 1.3 intervals between the pairs of beats.  

For the periodicity analyses, we want to transform the the discrete onsets to continuous time representation with an uniform sampling rate. This makes the comparisons of the models easier and allows to handle time more explicitly. Here we transform the onsets from one performance into onsets represented by time and gaussian distributions centred on the onsets. 

```{r continuous_rep,echo=TRUE,fig.width=5.5,fig.height=1.8,fig.cap='Onset curve (continuous representation) for bass.'}
fig12 <- gaussify_onsets(extract$Guitar,sr=250, time=TRUE, plot = TRUE)
```


In this section we use multiple techniques such as auto-correlation, fast fourier transform (FFT), wavelet analysis and onset differences to estimate the periodicity of the onset structures.

### 2.4.1 Estimate periodicity using autocorrelation

```{r acf,echo=TRUE,fig.width=4.0,fig.height=3.0,fig.cap='Autocorrelation of the onset signal between 0 and 0.8 seconds.'}
CSS_Song2 <- ungroup(CSS_Song2) # drop grouping structure
P1 <- periodicity(CSS_Song2,
                  instr = 'Guitar', method='acf',
                  freq_range = c(0,1))
print(P1$Figure)
PM <- periodicity_moments(P1$Curve)
print(PM$Per)
BPM <- period_to_BPM(PM$Per)
print(BPM)
```

Figure 6 displays the auto-correlation function for the onsets and the next calculation (`periodicity_moments`) takes different descriptors of the function (such as the _period_, which is the highest peak in the plot). In this example it is `r PM$Per * 1000` in milliseconds. This is slightly different from the early calculation of the typical onset time differences reported in Table 4, which suggested that the mean onset time difference for guitar was 224 ms and the median was 245 ms. In terms of beats per minute (BPM), this is `r round(BPM)`, which was obtained via `period_to_BPM` function. This tempo in BPM is very likely misleading as the beat division it used is based on 16 sub-division in a cycle, which suggests that guitar plays eight notes (quavers) so the tempo in BPM in is more probably half of the suggested, `r round(BPM/2)` BPM.



### 2.4.2 Create signals varying in periodicity

```{r periodic_examples,fig.width=8,fig.height=5,fig.cap='Four example signals.'}
## Example 1: Random
ex1 <- runif(120,min = 0,max=60)

## Example 2: Accelerating sequence
ex2<-NULL
i<-0.1
for (k in 1:6) {
  tmp <- seq(0,10,by=0.92-i)
  ex2 <-c(ex2,tmp+(k-1)*10)
  i<-i+0.1
}

## Example 3: Periodic
ex3 <- seq(0.5,60,by=0.5)

## Example 4: Period with random noise
ex4<- ex3 + runif(120,min=0.01,max = 0.2)-0.1

## Put them into one data.frame
df <- data.frame(Random = ex1, Accelerating = ex2, 
                 Periodic2Hz = ex3, Periodic2HzNoise = ex4)
fig13 <- plot_timeline(data = df, instr = as.character(names(df)))
print(fig13)
```

### 2.4.4 Period estimation with different techniques

Let's apply four different techniques to the periodic signal that contains a bit of noise (`ex4`).

```{r,fig.width=8,fig.height=5,fig.cap='Periodicity estimation with ACF, FFT, Wavelet and onset time difference.',warning=FALSE,message=FALSE}
P1 <- periodicity(df = data.frame(onset = ex4), 
                  instr = 'onset', method='acf',
                  freq_range = c(0,1),
                  title = '2 Hz signal with ACF')
P2 <- periodicity(df = data.frame(onset = ex4), 
                  instr = 'onset', method='fft',
                  freq_range = c(0,1),
                  title = '2 Hz signal with FFT')
P3 <- periodicity(df = data.frame(onset = ex4), 
                  instr = 'onset', method='wavelet',
                  freq_range = c(0,1),
                  title = '2 Hz signal with Wavelet')
P4 <- periodicity(df = data.frame(onset = ex4), 
                  instr = 'onset', method='diff',
                  freq_range = c(0,1),
                  title = '2 Hz signal with onset time difference')

library(cowplot)
plot_grid(P1$Figure, P2$Figure, P3$Figure, P4$Figure, ncol = 2)
```

Despite the different shape of the function, all methods are able to find the asssumed 2 Hz (0.5 s) peak with `periodicity_moments`, provided that we choose the appropriate method of picking the peak of the curve (for auto-correlation, the default option of `max` would yield half the periodicity (1 s) in this case).

```{r report_periodicity}
P1M <- periodicity_moments(P1$Curve,method='first')
cat(paste('Dominant periodicity according to ACF:',round(P1M$Per*1000),'ms'))
P2M <- periodicity_moments(P2$Curve,method='max')
cat(paste('Dominant periodicity according to FFT:',round(P2M$Per*1000),'ms'))
P3M <- periodicity_moments(P3$Curve,method='max')
cat(paste('Dominant periodicity according to Wavelet:',round(P3M$Per*1000),'ms'))
P4M <- periodicity_moments(P4$Curve,method='max')
cat(paste('Dominant periodicity according to Difference:',round(P4M$Per[1]*1000),'ms'))
```
### 2.4.3 Degree of periodicity with different techniques

We can also ask how different are these example signals in terms of their periodicity.

```{r report_periodicity_max,echo=TRUE,results='asis'}
P_ALL <- matrix(0,4,4)
P_METHOD <-c('acf','fft','wavelet','diff')
for (k in 1:4) {
  for (l in 1:length(P_METHOD)) {
    P <- periodicity(df = df, instr = as.character(names(df)[k]),
                     method = P_METHOD[l],freq_range = c(0,1))
    PM <- periodicity_moments(P$Curve,method='max')
    P_ALL[k,l]<-as.numeric(PM$Max[1])
  }
}

rownames(P_ALL) <- names(df)
colnames(P_ALL) <- P_METHOD
print(knitr::kable(P_ALL,digits = 3,
                   caption = 'Maximum amplitude of the peak 
                   period across four signals and methods.'))
```

Table 8 suggests similar ranking where the periodic signal has the clearest periodicity, periodic with noise is the second (except in difference-based method), and the random signal is the worst. These examples were of course artificial, but they serve to illustrate two aspects of the periodicity estimation, the actual periodicity and its amplitude. Other statistical moments such as skewness and kurtosis can also be explored from this representation. Periodicity in the actual music performances will be much more nuanced and usually contains multiple hierarchies, so picking the right measures to describe these aspects of the beat structures requires further work.

## Conclusions

Short summary to be written.

# Acknowledgements

We acknowledge contributions from IEMP Fellows (RP, etc) and Simone Tarsitani here. And Kelly Jakubowski.


# References
